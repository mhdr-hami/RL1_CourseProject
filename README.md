# RL1_CourseProject
Graduate course at the University of Alberta.

Empirical Study of Differential Q-learning on Continuing Control Tasks,
Differential Q-learning is a recently developed average reward algorithm for off policy control. We conduct an empirical study of differential Q-learning on two continuing tasks, Catch and Pendulum, in the linear function approximation setting. To the best of our knowledge, this is the first comparison between discounted and differential Q-learning in the literature. We provide performance results and sensitivity analyses. Our results show that differential Q-learning is no worse than discounted Q-learning on Pendulum but is not a suitable algorithm for Catch.
